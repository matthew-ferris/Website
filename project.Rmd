---
title: "Using Machine Learning Classification Techniques to Predict Going Concern Opinions"
author: "Matt Ferris"
date: "November 26, 2021"
output: 
  distill::distill_article
---

```{r Load Libraries,include=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
library(lattice)
library(ggplot2)
library(caret)
library(tidyverse)
library(corrplot)
library(stringr)
library(RANN)
```

```{r Load Data, message=FALSE, include=FALSE, warning=FALSE,echo=FALSE}
setwd("~/Desktop/Analytics/Website")

Data<-read.csv("Data.csv",na.strings = ".")
attach(Data)
Data$GOING_CONCERN<-as.factor(Data$GOING_CONCERN)
```

Using a dataset obtained through Dr. Berglund at Mississippi State University, I plan on using machine learning to classify the likelihood that a Going Concern opinion will be issued by an auditor. 

To get started, I wanted to see the distribution of the dependent variable, which would be the Going Concern attribute. 

```{r Dependent Variable Distribution Pt. 1, echo=TRUE}
table(Data$GOING_CONCERN)
```

You can see that the distribution is very heavily skewed. Of the nearly 56,000 observations, just under 6,500 of them issued a Going Concern opinion. 

After reviewing the dataset some more, I noticed that there were a relatively large amount of NAs in the observations. Using this formula, you can see the percentage of the data that is NA. 

```{r How much NA?, echo=TRUE}
sum(is.na(Data))/prod(dim(Data))
```

You can see that roughly 10.5% of the cells are NA. There are a few ways to continue, such as different imputation techniques to make "estimates" of what those empty cells should be. However, for the sake of not murdering my computer, I have elected to simply omit NAs from the data. 

```{r Remove NAs, echo=TRUE}
Data<-na.omit(Data)
```

After omitting the NAs, I wanted to see the new distribution of the dependent variable. 

```{r Dependent Variable Distribution Pt. 2, echo=TRUE}
table(Data$GOING_CONCERN)
```

The dataset has now been reduced from 56,000 observations to 40,500. Of those entries removed, a large percentage of them were those that had Going Concern opinions.

**Note: Do I need to over-sample? Such as using SMOTE or a similar function?**

To use machine learning to make the prediction of whether a Going Concern will be issued, I will use K-Nearest Neighbors classification. First, I will need to partition the data into two different sets: the first as a "training" set, which 'trains' the algorithm, and the second as a "testing" set, which will be used to test the fit of the model. Using the KNN method to make the predictions, I will then visualize the results in a confusion matrix. 

```{r Knn Classification,include=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
#split the test/train data
trainIndex <- createDataPartition(Data$GOING_CONCERN, p = .5, list = FALSE, times = 1)
#grab the data
DataTrain <- Data[ trainIndex,]
DataTest  <- Data[-trainIndex,]

preProcValues <- preProcess(DataTrain, method = c("center", "scale"))
trainTransformed <- predict(preProcValues, DataTrain)

preProcValues <- preProcess(DataTest, method = c("center", "scale"))
testTransformed <- predict(preProcValues, DataTest)

knn_fit<-train(GOING_CONCERN~MATCHFY_BALSH_ASSETS+MATCHFY_BALSH_BOOK_VAL+MATCHFY_CSHFLST_CHANGE_TTM+MATCHFY_CSHFLST_OP_ACT_TTM+MATCHFY_INCMST_NETINC_TTM+PRIORFY_INCMST_NETINC_TTM+PRIORFY_BALSH_BOOK_VAL+MATCHFY_SUM_AUDFEES+PRIORFY_SUM_AUDFEES+CIK_Code,
               data=trainTransformed,
               method="knn",
               tuneGrid=data.frame(k=4))

knn_pred<-predict(knn_fit,testTransformed)
confusionMatrix(knn_pred,testTransformed$GOING_CONCERN)
```

We can see that this model did not perform spectacularly. This is likely due to the data limitations and not having a direct correlation between the independent variables and the dependent variable. 

```{r cluster analysis,include=FALSE,echo=FALSE,message=FALSE,warning=FALSE, eval=FALSE}
#cluster
#trainTransformed<-subset(trainTransformed,select = -c(AUDITOR_STATE))
Clusters<-kmeans(trainTransformed,centers=4)
Clusterdata<-trainTransformed
Clusterdata$Cluster<-as.factor(Clusters$cluster)

ggplot(data=Clusterdata,mapping = aes(x=MATCHFY_CSHFLST_OP_ACT_TTM,y=MATCHFY_INCMST_NETINC_TTM,color=Cluster))+geom_point(alpha=0.5)

ggplot(data=Clusterdata,mapping = aes(x=MATCHFY_CSHFLST_OP_ACT_TTM,y=MATCHFY_INCMST_NETINC_TTM,color=Cluster))+geom_point(alpha=0.5)+facet_wrap(~GOING_CONCERN)
```


