---
title: "Audit Dataset"
author: "Matt Ferris"
date: "11/24/2021"
output: html_document
---

```{r Load Libraries,include=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
if (!require("lattice")) install.packages("lattice")
library(lattice)
library(ggplot2)
if (!require("caret")) install.packages("caret")
library(caret)
if (!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
if (!require("corrplot")) install.packages("corrplot")
library(corrplot)
if (!require("stringr")) install.packages("stringr")
library(stringr)
if (!require("RANN")) install.packages("RANN")
library(RANN)
```

```{r Load Data, message=FALSE, include=FALSE, warning=FALSE,echo=FALSE}
setwd("~/Desktop/Analytics/Website")

Data<-read.csv("Data.csv",na.strings = ".")
attach(Data)
Data$GOING_CONCERN<-as.factor(Data$GOING_CONCERN)
```

Using a dataset obtained through Dr. Berglund at Mississippi State University, I plan on using machine learning to classify the likelihood of a Going Concern opinion will be issued by an auditor. 

To get started, I wanted to see the distribution of the dependent variable, which would be the Going Concern attribute. 

```{r Dependent Variable Distribution Pt. 1, echo=TRUE}
table(Data$GOING_CONCERN)
```

You can see that the distribution is very heavily skewed. Of the nearly 56,000 observations, just under 6,500 of them issued a Going Concern opinion. 

After reviewing the dataset some more, I noticed that there were a relatively large amount of NAs in the observations. Using this formula, you can see the percentage of the data that is NA. 

```{r How much NA?, echo=TRUE}
sum(is.na(Data))/prod(dim(Data))
```

You can see that roughly 10.5% of the cells are NA. There are a few ways to continue, such as different imputation techniques to make "estimates" of what those empty cells should be. However, for the sake of not murdering my computer, I have elected to simply omit NAs from the data. 

```{r Remove NAs, echo=TRUE}
Data<-na.omit(Data)
```

After omitting the NAs, I wanted to see the new distribution of the dependent variable. 

```{r Dependent Variable Distribution Pt. 2, echo=TRUE}
table(Data$GOING_CONCERN)
```

The dataset has now been reduced from 56,000 observations to 40,500. Of those entries removed, a large percentage of them were those that had Going Concern opinions.

**Note: Do I need to over-sample? Such as using SMOTE or a similar function?**

```{r Knn Classification,include=FALSE,echo=FALSE,message=FALSE,warning=FALSE, eval=FALSE}
#split the test/train data
trainIndex <- createDataPartition(Data$GOING_CONCERN, p = .5, list = FALSE, times = 1)
#grab the data
DataTrain <- Data[ trainIndex,]
DataTest  <- Data[-trainIndex,]

preProcValues <- preProcess(DataTrain, method = c("center", "scale"))
trainTransformed <- predict(preProcValues, DataTrain)

preProcValues <- preProcess(DataTest, method = c("center", "scale"))
testTransformed <- predict(preProcValues, DataTest)

knn_fit<-train(GOING_CONCERN~MATCHFY_BALSH_ASSETS+MATCHFY_BALSH_BOOK_VAL+MATCHFY_CSHFLST_CHANGE_TTM+MATCHFY_CSHFLST_OP_ACT_TTM+MATCHFY_INCMST_NETINC_TTM+PRIORFY_INCMST_NETINC_TTM+PRIORFY_BALSH_BOOK_VAL+MATCHFY_SUM_AUDFEES+PRIORFY_SUM_AUDFEES+CIK_Code,
               data=trainTransformed,
               method="knn",
               tuneGrid=data.frame(k=4))

knn_fit

knn_pred<-predict(knn_fit,testTransformed)
confusionMatrix(knn_pred,testTransformed[1])
```

```{r cluster analysis,include=FALSE,echo=FALSE,message=FALSE,warning=FALSE, eval=FALSE}
#cluster
#trainTransformed<-subset(trainTransformed,select = -c(AUDITOR_STATE))
Clusters<-kmeans(trainTransformed,centers=4)
Clusterdata<-trainTransformed
Clusterdata$Cluster<-as.factor(Clusters$cluster)

ggplot(data=Clusterdata,mapping = aes(x=MATCHFY_CSHFLST_OP_ACT_TTM,y=MATCHFY_INCMST_NETINC_TTM,color=Cluster))+geom_point(alpha=0.5)

ggplot(data=Clusterdata,mapping = aes(x=MATCHFY_CSHFLST_OP_ACT_TTM,y=MATCHFY_INCMST_NETINC_TTM,color=Cluster))+geom_point(alpha=0.5)+facet_wrap(~GOING_CONCERN)
```


